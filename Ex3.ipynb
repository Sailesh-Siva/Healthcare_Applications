{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "275749ee-d293-4099-9892-1c0da585cb4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   PatientID  Age Gender     Diagnosis\n",
      "0          1   34      M      Diabetes\n",
      "1          2   45      F  Hypertension\n",
      "2          3   23      F        Asthma\n",
      "3          4   50      M      Diabetes\n",
      "4          5   40      M  Hypertension\n",
      "   PatientID  Age  Gender     Diagnosis\n",
      "0          1   34       0      Diabetes\n",
      "1          2   45       1  Hypertension\n",
      "2          3   23       1        Asthma\n",
      "3          4   50       0      Diabetes\n",
      "4          5   40       0  Hypertension\n",
      "   PatientID  Age  Gender  Diagnosis_Asthma  Diagnosis_Diabetes  \\\n",
      "0          1   34       0             False                True   \n",
      "1          2   45       1             False               False   \n",
      "2          3   23       1              True               False   \n",
      "3          4   50       0             False                True   \n",
      "4          5   40       0             False               False   \n",
      "\n",
      "   Diagnosis_Hypertension  \n",
      "0                   False  \n",
      "1                    True  \n",
      "2                   False  \n",
      "3                   False  \n",
      "4                    True  \n",
      "['patient history hypertension diabetes prescribed medication x', 'asthma diagnosis confirmed patient advised use inhaler daily', 'hypertension patient needs regular monitoring blood pressure', 'diabetes patient recommended diet exercise', 'patient diagnosed hypertension medication prescribed']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Sailesh\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\n# Vectorize the text using TF-IDF\\nvectorizer = TfidfVectorizer(max_features=10)\\nX_tfidf = vectorizer.fit_transform(cleaned_notes).toarray()\\npd.DataFrame(X_tfidf, columns=vectorizer.get_feature_names_out()).head()\\n\\n# Apply PCA to structured data\\npca = PCA(n_components=2)\\nstructured_data_pca = pca.fit_transform(structured_data.drop('PatienxtID', axis=1))\\n\\n# Plot PCA results\\nplt.figure(figsize=(8, 6))\\nplt.scatter(structured_data_pca[:, 0], structured_data_pca[:, 1], c='blue', marker='o')\\nplt.title('PCA of Structured Clinical Data')\\nplt.xlabel('Principal Component 1')\\nplt.ylabel('Principal Component 2')\\nplt.grid(True)\\nplt.show()\\n\\n# Apply KMeans clustering to text data\\nkmeans = KMeans(n_clusters=2, random_state=0).fit(X_tfidf)\\n\\n# Plot word cloud for each cluster\\nfor i in range(2):\\n    cluster_words = ' '.join([cleaned_notes[j] for j in range(len(cleaned_notes)) if kmeans.labels_[j] == i])\\n    wordcloud = WordCloud(width=800, height=400, background_color='white').generate(cluster_words)\\n    plt.figure(figsize=(10, 5))\\n    plt.imshow(wordcloud, interpolation='bilinear')\\n    plt.axis('off')\\n    plt.title(f'Word Cloud for Cluster {i}')\\n    plt.show()\\n\""
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "import nltk\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "from wordcloud import WordCloud\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# Load structured clinical data\n",
    "structured_data = pd.DataFrame({\n",
    "    'PatientID': [1, 2, 3, 4, 5],\n",
    "    'Age': [34, 45, 23, 50, 40],\n",
    "    'Gender': ['M', 'F', 'F', 'M', 'M'],\n",
    "    'Diagnosis': ['Diabetes', 'Hypertension', 'Asthma', 'Diabetes', 'Hypertension']\n",
    "})\n",
    "print(structured_data.head())\n",
    "\n",
    "# Load unstructured clinical data (clinical notes)\n",
    "unstructured_data = [\n",
    "    \"Patient has a history of hypertension and diabetes. Prescribed medication X.\",\n",
    "    \"Asthma diagnosis confirmed. Patient advised to use inhaler daily.\",\n",
    "    \"Hypertension patient. Needs regular monitoring of blood pressure.\",\n",
    "    \"Diabetes patient. Recommended diet and exercise.\",\n",
    "    \"Patient diagnosed with hypertension. Medication Y prescribed.\"\n",
    "]\n",
    "structured_data.head()\n",
    "\n",
    "# Check for missing values\n",
    "structured_data.isnull().sum()\n",
    "\n",
    "# Encode categorical variables\n",
    "structured_data['Gender'] = structured_data['Gender'].map({'M': 0, 'F': 1})\n",
    "print(structured_data.head())\n",
    "structured_data = pd.get_dummies(structured_data, columns=['Diagnosis'])\n",
    "print(structured_data.head())\n",
    "structured_data.head()\n",
    "\n",
    "# Text preprocessing function\n",
    "def preprocess_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'\\d+', '', text)  # Remove numbers\n",
    "    text = re.sub(r'\\W+', ' ', text)  # Remove non-word characters\n",
    "    text = ' '.join([word for word in text.split() if word not in stopwords.words('english')])\n",
    "    return text\n",
    "\n",
    "# Apply preprocessing to clinical notes\n",
    "cleaned_notes = [preprocess_text(note) for note in unstructured_data]\n",
    "print(cleaned_notes)\n",
    "\"\"\"\n",
    "# Vectorize the text using TF-IDF\n",
    "vectorizer = TfidfVectorizer(max_features=10)\n",
    "X_tfidf = vectorizer.fit_transform(cleaned_notes).toarray()\n",
    "pd.DataFrame(X_tfidf, columns=vectorizer.get_feature_names_out()).head()\n",
    "\n",
    "# Apply PCA to structured data\n",
    "pca = PCA(n_components=2)\n",
    "structured_data_pca = pca.fit_transform(structured_data.drop('PatienxtID', axis=1))\n",
    "\n",
    "# Plot PCA results\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(structured_data_pca[:, 0], structured_data_pca[:, 1], c='blue', marker='o')\n",
    "plt.title('PCA of Structured Clinical Data')\n",
    "plt.xlabel('Principal Component 1')\n",
    "plt.ylabel('Principal Component 2')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Apply KMeans clustering to text data\n",
    "kmeans = KMeans(n_clusters=2, random_state=0).fit(X_tfidf)\n",
    "\n",
    "# Plot word cloud for each cluster\n",
    "for i in range(2):\n",
    "    cluster_words = ' '.join([cleaned_notes[j] for j in range(len(cleaned_notes)) if kmeans.labels_[j] == i])\n",
    "    wordcloud = WordCloud(width=800, height=400, background_color='white').generate(cluster_words)\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.imshow(wordcloud, interpolation='bilinear')\n",
    "    plt.axis('off')\n",
    "    plt.title(f'Word Cloud for Cluster {i}')\n",
    "    plt.show()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59daa4f5-7ec5-4bf1-a70c-9c103b5da67c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
